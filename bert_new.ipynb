{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\LAKSHMI SRI LASYA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary libraries\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Variables\n",
    "vocab_size = 3000\n",
    "embedding_dim = 32\n",
    "max_length = 60\n",
    "truncation_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "training_size = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      "1    15576\n",
      "Name: count, dtype: int64 labels\n",
      "0    16000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataList = []\n",
    "sentences = []\n",
    "labels = []\n",
    "# Stopwords should be removed or excluded from the given text so that more \n",
    "# focus can be given to those words which define the meaning of the text.\n",
    "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
    "\n",
    "def loadDataset(filename):\n",
    "  d=[]\n",
    "  with open(filename, 'r') as f:\n",
    "      datastore = json.load(f)\n",
    "  for item in datastore:\n",
    "    sentence = item['data']\n",
    "    label = item['is_sensitive']\n",
    "    for word in stopwords: #Remove stop words in sentence\n",
    "      token = \" \" + word + \" \"\n",
    "      sentence = sentence.replace(token, \" \")\n",
    "    d.append([sentence,label])\n",
    "  return d\n",
    "# Loading both sensitive and non-sensitive dataset\n",
    "sen=loadDataset(\"SensitiveDataset.json\")\n",
    "nonsen=loadDataset(\"NonSensitiveDatasetnew.json\")\n",
    "\n",
    "import pandas as pd\n",
    "sen=pd.DataFrame(data=sen,columns=['sentences','labels'])\n",
    "nonsen=pd.DataFrame(data=nonsen,columns=['sentences','labels'])\n",
    "print(sen['labels'].value_counts(),nonsen['labels'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaliyah,   123456,    aaliyah@gmail.com,  490...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaren,   12345,    aaren@yahoo.com,  8292544966</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aarika,   123456789,    aarika@hotmail.com,  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaron,   iloveyou,    aaron@aol.com,  5834106229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aartjan,   princess,    aartjan@hotmail.co.uk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  labels\n",
       "0   aaliyah,   123456,    aaliyah@gmail.com,  490...       1\n",
       "1    aaren,   12345,    aaren@yahoo.com,  8292544966       1\n",
       "2   aarika,   123456789,    aarika@hotmail.com,  ...       1\n",
       "3   aaron,   iloveyou,    aaron@aol.com,  5834106229       1\n",
       "4   aartjan,   princess,    aartjan@hotmail.co.uk...       1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming df1 and df2 are your two dataframes\n",
    "df= pd.concat([sen, nonsen], axis=0)  # Concatenate along rows (axis=0)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quills begins Paris Reign Terror, incarcerated...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bathsheba,   birthday,    bathsheba@virgilio....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frankie J. Parker Los Angeles radio disc jocke...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aurie,   tazmania,    aurie@bigpond.com,  385...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pan number:dtpd6162ivyl, full name:dharamaraj ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  labels\n",
       "0  Quills begins Paris Reign Terror, incarcerated...       0\n",
       "1   bathsheba,   birthday,    bathsheba@virgilio....       1\n",
       "2  Frankie J. Parker Los Angeles radio disc jocke...       0\n",
       "3   aurie,   tazmania,    aurie@bigpond.com,  385...       1\n",
       "4  pan number:dtpd6162ivyl, full name:dharamaraj ...       1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.sample(frac=1).reset_index(drop=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15576, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sen=df[df['labels']==1]\n",
    "df_sen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_non=df[df['labels']==0]\n",
    "df_non.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15576, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_non_downsampled = df_non.sample(df_sen.shape[0])\n",
    "df_non_downsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31152, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced = pd.concat([df_non_downsampled, df_sen])\n",
    "df_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "0    15576\n",
       "1    15576\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8430      blinnie,   friends1,    blinnie@chello.nl,  6...\n",
       "20674    Boyce, expert sport falconry son FBI office em...\n",
       "8309     Davey Osborne (Henry Thomas) 11-year-old boy l...\n",
       "17473    Middle-aged Mrs. Livingston Baldwin Crane (Edn...\n",
       "Name: sentences, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(df_balanced['sentences'],df_balanced['labels'],stratify=df_balanced['labels'])\n",
    "X_train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LAKSHMI SRI LASYA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in X_train]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of word index: 112009\n",
      "Saving the word index as JSON\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(\"Size of word index:\", len(word_index))\n",
    "\n",
    "with open(\"word_index.json\", \"w\") as outfile:  \n",
    "    json.dump(word_index, outfile)\n",
    "    print(\"Saving the word index as JSON\")\n",
    "\n",
    "training_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=truncation_type)\n",
    "\n",
    "validation_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "validation_padded = pad_sequences(validation_sequences, maxlen=max_length, padding=padding_type, truncating=truncation_type)\n",
    "\n",
    "#create attention masks for training and validation\n",
    "attention_masks = []\n",
    "for seq in training_padded:\n",
    "  seq_mask = [int(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask)\n",
    "\n",
    "attention_masks_val = []\n",
    "for seq in validation_padded:\n",
    "  seq_mask = [int(i>0) for i in seq]\n",
    "  attention_masks_val.append(seq_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = torch.tensor(training_padded.tolist())\n",
    "train_mask = torch.tensor(attention_masks)\n",
    "train_y = torch.tensor(y_train.tolist())\n",
    "\n",
    "test_seq = torch.tensor(validation_padded.tolist())\n",
    "test_mask = torch.tensor(attention_masks_val)\n",
    "test_y = torch.tensor(y_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "#define a batch size\n",
    "batch_size = 32\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq,train_mask,train_y)\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(test_seq,test_mask,test_y)\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()      \n",
    "        self.bert = bert \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        # relu activation function\n",
    "        self.relu =  nn.ReLU()\n",
    "        # dense layer 1\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "        # dense layer 2 (Output layer)\n",
    "        self.fc2 = nn.Linear(512,2)\n",
    "        #softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):    \n",
    "        #pass the inputs to the model  \n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
    "        x = self.fc1(cls_hs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        # output layer\n",
    "        x = self.fc2(x)\n",
    "        # apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a tensor model\n",
    "model = BERT_Arch(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# Move the model to the device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = [1.0, 1.0]\n",
    "\n",
    "# converting list of class weights to a tensor\n",
    "weights= torch.tensor(class_weights,dtype=torch.float)\n",
    "\n",
    "# push to GPU\n",
    "weights = weights.to(device)\n",
    "\n",
    "# define the loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) \n",
    "\n",
    "# number of training epochs\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "#defining epochs\n",
    "epochs = 1\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "#for each epoch\n",
    "for epoch in range(epochs):   \n",
    "    # function to train the model\n",
    "    def train():\n",
    "        model.train()\n",
    "        total_loss, total_accuracy = 0, 0\n",
    "        # empty list to save model predictions\n",
    "        total_preds=[]\n",
    "        # iterate over batches\n",
    "        for step,batch in enumerate(train_dataloader):\n",
    "            # progress update after every 50 batches.\n",
    "            if step % 50 == 0 and not step == 0:\n",
    "                print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "            # push the batch to gpu\n",
    "            batch = [torch.tensor(r).to(device) for r in batch]\n",
    "            sent_id, mask, labels = batch\n",
    "            # clear previously calculated gradients \n",
    "            model.zero_grad()        \n",
    "            # get model predictions for the current batch\n",
    "            preds = model(sent_id, mask)\n",
    "            # compute the loss between actual and predicted values\n",
    "            loss = cross_entropy(preds, labels)\n",
    "            # add on to the total loss\n",
    "            total_loss = total_loss + loss.item()\n",
    "            # backward pass to calculate the gradients\n",
    "            loss.backward()\n",
    "            # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            #defining optimizer\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-5)\n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "            # model predictions are stored on GPU. So, push it to CPU\n",
    "            preds=preds.detach().cpu().numpy()\n",
    "            # append the model predictions\n",
    "            total_preds.append(preds)\n",
    "        # compute the training loss of the epoch\n",
    "        avg_loss = total_loss / len(train_dataloader)\n",
    "        # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "        # reshape the predictions in form of (number of samples, no. of classes)\n",
    "        total_preds  = np.concatenate(total_preds, axis=0)\n",
    "        # returns the average loss and total predictions\n",
    "        return avg_loss, total_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():   \n",
    "    print(\"\\nEvaluating...\")\n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(validation_padded):\n",
    "        # Progress update every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            #elapsed = format_time(time.time() - t0)\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "        # push the batch to gpu\n",
    "        batch = [torch.tensor(r).to(device) for r in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask)\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = cross_entropy(preds,labels)\n",
    "            total_loss = total_loss + loss.item()\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            total_preds.append(preds)\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader) \n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LAKSHMI SRI LASYA\\AppData\\Local\\Temp\\ipykernel_9912\\2999930525.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = [torch.tensor(r).to(device) for r in batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    50  of    731.\n",
      "  Batch   100  of    731.\n",
      "  Batch   150  of    731.\n",
      "  Batch   200  of    731.\n",
      "  Batch   250  of    731.\n",
      "  Batch   300  of    731.\n",
      "  Batch   350  of    731.\n",
      "  Batch   400  of    731.\n",
      "  Batch   450  of    731.\n",
      "  Batch   500  of    731.\n",
      "  Batch   550  of    731.\n",
      "  Batch   600  of    731.\n",
      "  Batch   650  of    731.\n",
      "  Batch   700  of    731.\n",
      "\n",
      "Training Loss: 0.457\n"
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "#defining epochs\n",
    "epochs = 1\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    #train model\n",
    "    train_loss,_ = train()\n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#evaluate model\\nvalid_losses=[]\\nvalid_loss,total_preds= evaluate()\\n#save the best model\\nif valid_loss < best_valid_loss:\\n    best_valid_loss = valid_loss\\n    torch.save(model.state_dict(), 'saved_weights.pt')\\nvalid_losses.append(valid_loss)\\nprint(f'Validation Loss: {valid_loss:.3f}')\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#evaluate model\n",
    "valid_losses=[]\n",
    "valid_loss,total_preds= evaluate()\n",
    "#save the best model\n",
    "if valid_loss < best_valid_loss:\n",
    "    best_valid_loss = valid_loss\n",
    "    torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "valid_losses.append(valid_loss)\n",
    "print(f'Validation Loss: {valid_loss:.3f}')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# get predictions for test data\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      4\u001b[0m     preds \u001b[38;5;241m=\u001b[39m model(test_seq\u001b[38;5;241m.\u001b[39mto(device), test_mask\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m      5\u001b[0m     preds \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# get predictions for test data\n",
    "with torch.no_grad():\n",
    "    preds = model(test_seq.to(device), test_mask.to(device))\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "  \n",
    "\n",
    "# model's performance\n",
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#print confusion matrix\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m----> 3\u001b[0m confusion_matrix(\u001b[43mtest_y\u001b[49m, preds)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#save the model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved_weights.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_y' is not defined"
     ]
    }
   ],
   "source": [
    "#print confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(test_y, preds)\n",
    "\n",
    "#save the model\n",
    "torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "\n",
    "#load weights\n",
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()\n",
    "\n",
    "import seaborn as sns\n",
    "sns.heatmap(cm,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
